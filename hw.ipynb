{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "940b98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark\").getOrCreate() #INITIALIZE SPARK SESSION\n",
    "\n",
    "fileList = [] \n",
    "spark = SparkSession.builder.appName(\"Spark\").getOrCreate()\n",
    "\n",
    "for f in os.listdir(fileDir):\n",
    "    if f!=\".DS_Store\":\n",
    "        file = os.path.join(fileDir, f)\n",
    "        for year_file in os.listdir(file):\n",
    "            if year_file != \".ipynb_checkpoints\" and year_file != \".DS_Store\":\n",
    "                fileList.append(file+\"/\"+year_file)       #ALL FILE NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f6ddc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\",\"true\").option(\"delimiter\",\",\").csv(fileList) #CREATING THE DATAFRAME\n",
    "\n",
    "#COUNT FOR PART 4 (for the NULL values) We do this before we drop the NULL Values \n",
    "\n",
    "df_2019 = df.filter(year(col(\"DATE\")) == 2019)  # Filter rows for 2019\n",
    "\n",
    "total2019 = df_2019.filter(year(col(\"DATE\")) == 2019).count()\n",
    "null2019 = df_2019.filter(col(\"GUST\").isNull()).count()\n",
    "out2019 = df_2019.filter(col(\"GUST\") == 999).count()\n",
    "miss2019 = null2019 + out2019\n",
    "percent = miss2019/total2019 * 100\n",
    "\n",
    "\n",
    "df = df.dropna() #DROP ALL NULL COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "332c7ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------+-----------+--------------------+\n",
      "|YEAR|max(MAX)|first(STATION)|first(DATE)|         first(NAME)|\n",
      "+----+--------+--------------+-----------+--------------------+\n",
      "|2010|      75|   99407099999| 2010-08-15|DESTRUCTION IS. W...|\n",
      "|2011|      88|   01046099999| 2011-07-09|       SORKJOSEN, NO|\n",
      "|2012|      72|   01023099999| 2012-07-05|       BARDUFOSS, NO|\n",
      "|2013|      81|   01001499999| 2013-08-02|      SORSTOKKEN, NO|\n",
      "|2014|      90|   01023099999| 2014-07-10|       BARDUFOSS, NO|\n",
      "|2015|      72|   01025099999| 2015-07-30|          TROMSO, NO|\n",
      "|2016|      77|   01023199999| 2016-07-21|         DRAUGEN, NO|\n",
      "|2017|      79|   01023099999| 2017-06-09|       BARDUFOSS, NO|\n",
      "|2018|      84|   01025099999| 2018-07-29|          TROMSO, NO|\n",
      "|2019|      79|   01023099999| 2019-07-21|       BARDUFOSS, NO|\n",
      "|2020|      80|   01023099999| 2020-06-22|       BARDUFOSS, NO|\n",
      "|2021|      88|   01065099999| 2021-07-05|        KARASJOK, NO|\n",
      "|2022|      86|   02095099999| 2022-07-01|          PAJALA, SW|\n",
      "+----+--------+--------------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EXTRACT YEAR FROM DATE \n",
    "dfn = df.withColumn(\"YEAR\", year(df[\"DATE\"])).withColumn(\"DATE\", date_format(\"DATE\",\"yyyy-MM-dd\"))#month(df[\"DATE\"], date_format(\"DATE\",\"yyyy-MM-dd\")))\n",
    "dfn = dfn.dropna() #REMOVE THE NULLS\n",
    "\n",
    "#PART 1: Find the hottest day (column MAX) for each year, and provide the corresponding station code, station name and the date (columns STATION, NAME, DATE).  \n",
    "dfn = dfn.filter(dfn.MAX != 9999)\n",
    "\n",
    "(dfn.withColumn(\"MAX\", col(\"MAX\").cast(\"Decimal\")).orderBy(desc(\"MAX\"))\n",
    ".withColumn(\"DATE\", date_format(\"DATE\", \"yyyy-MM-dd\"))\n",
    ".groupBy(year(\"DATE\").alias(\"YEAR\")).agg(max(\"MAX\"), first(\"STATION\"), first(\"DATE\"), first(\"NAME\"))\n",
    ".orderBy(asc(\"YEAR\")).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "976a5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+------+\n",
      "|    STATION|      DATE|        NAME|   MIN|\n",
      "+-----------+----------+------------+------+\n",
      "|01008099999|2020-01-03|LONGYEAR, SV|   0.1|\n",
      "+-----------+----------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PART 2: Find the coldest day (column MIN) for the month of January across all years (2010 - 2022) ,and provide the corresponding station code, station name and the date (columns STATION,NAME, DATE). \n",
    "min_temps = df.filter(month(\"DATE\") == 1) \\\n",
    "    .groupBy(\"STATION\", \"DATE\", \"NAME\") \\\n",
    "    .agg(min(\"MIN\").alias(\"MIN\"))\n",
    "\n",
    "result = min_temps.orderBy(\"MIN\").limit(1)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0a03cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+-----+\n",
      "|    STATION|      DATE|      NAME| PRCP|\n",
      "+-----------+----------+----------+-----+\n",
      "|01025099999|2015-11-02|TROMSO, NO| 2.11|\n",
      "+-----------+----------+----------+-----+\n",
      "\n",
      "+-----------+----------+------------+-----+\n",
      "|    STATION|      DATE|        NAME| PRCP|\n",
      "+-----------+----------+------------+-----+\n",
      "|01008099999|2015-01-01|LONGYEAR, SV| 0.00|\n",
      "+-----------+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PART 3: Maximum and Minimum precipitation (column PRCP ) for the year 2015, and provide the corresponding station code, station name and the date (columns STATION, NAME, DATE). \n",
    "\n",
    "#max\n",
    "df = df.filter(df.PRCP != 99)\n",
    "\n",
    "max_precipitation = df.filter(year(\"DATE\") == 2015) \\\n",
    "    .groupBy(\"STATION\", \"DATE\", \"NAME\") \\\n",
    "    .agg(max(\"PRCP\").alias(\"PRCP\"))\n",
    "\n",
    "result = max_precipitation.orderBy(\"PRCP\", ascending=False).limit(1)\n",
    "result.show()\n",
    "\n",
    "#min\n",
    "min_precipitation = df.filter(year(\"DATE\") == 2015) \\\n",
    "    .groupBy(\"STATION\", \"DATE\", \"NAME\") \\\n",
    "    .agg(min(\"PRCP\").alias(\"PRCP\"))\n",
    "\n",
    "result = min_precipitation.orderBy(\"PRCP\").limit(1)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a677c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in the GUST Column: 82.87671232876713 %\n"
     ]
    }
   ],
   "source": [
    "#PART 4:Count percentage missing values for wind gust (column GUST) for the year 2019\n",
    "print(\"Percentage of missing values in the GUST Column: \" + str(percent) + \" %\") #VARIABLE DECLARED IN THE FIRST BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7f49cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------+----+------------------+\n",
      "|MONTH|              MEAN|MEDIAN|MODE|            STDDEV|\n",
      "+-----+------------------+------+----+------------------+\n",
      "|    1|15.210169491525424|  14.7|  57|12.653031460610185|\n",
      "|    2|13.577358490566034|  15.3|  48|13.186832615404862|\n",
      "|    3|15.023333333333333|  18.6|  54|15.829465837499537|\n",
      "|    4|23.329999999999995|  26.0|  56| 13.02209725617009|\n",
      "|    5| 36.21935483870967|  36.0|  53| 8.077246704851957|\n",
      "|    6| 47.42999999999999|  46.0|  54| 8.877190347997287|\n",
      "|    7| 52.88709677419356|  51.4|  52|  6.66378723291517|\n",
      "|    8| 49.37666666666669|  48.7|  50| 6.615066692379807|\n",
      "|    9| 40.92727272727273|  39.0|  11| 8.161138512375699|\n",
      "|   10|29.690322580645166|  24.3|  31|10.800072679962533|\n",
      "|   11|             31.01|  29.8|   9|   7.7448836157958|\n",
      "|   12|18.642857142857142|  19.5|  19| 9.619956934860543|\n",
      "+-----+------------------+------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PART 5: Find the mean, median, mode and standard deviation of the Temperature (column TEMP) for each month for the year 2020.\n",
    "results = df.filter(year(col(\"DATE\")) == 2020)\\\n",
    "            .groupBy(month(col(\"DATE\")).alias(\"MONTH\"))\\\n",
    "            .agg(\n",
    "                avg(col(\"TEMP\")).alias(\"MEAN\"),\n",
    "                expr(\"percentile_approx(TEMP, 0.5)\").alias(\"MEDIAN\"),\n",
    "                approx_count_distinct(col(\"TEMP\")).alias(\"MODE\"),\n",
    "                stddev(col(\"TEMP\")).alias(\"STDDEV\")\n",
    "            )\\\n",
    "            .orderBy(\"MONTH\")\n",
    "\n",
    "# display the results\n",
    "results.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
